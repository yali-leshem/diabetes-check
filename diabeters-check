{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "import torch\nfrom torch import nn\nfrom torch.utils.data import DataLoader\nimport pandas as pd\nimport torch\nfrom sklearn.model_selection import train_test_split\n\nclass data(torch.utils.data.Dataset):\n    def __init__(self, add_precents, data_src, parameters, target_cols):\n        # import data from csv file if necessary\n        self.data = data_src\n        # store info about data source\n        self.parameters = parameters   \n        self.target_cols = target_cols\n        self.data['Y'] = self.data['Y'].rank(method='first')\n        if add_precents == 0:\n            self.data['Class'] = pd.qcut(self.data['Y'], 100, labels = False) + 1\n        else:\n            self.data['Class'] = pd.qcut(self.data['Y'], 10, labels = False, duplicates='drop') + 1\n        \n\n    def __getitem__(self, idx):\n        # get the parameters x and the target y\n        x = self.data[self.parameters].iloc[idx]\n        y = self.data[self.target_cols].iloc[idx]\n        x = torch.tensor(x.values, dtype=torch.float32)\n        y = torch.tensor(y.values, dtype=torch.float32)\n\n        return x, y\n\n    def __len__(self):\n        return self.data.shape[0] # Returning length (shape)\n    \nclass dataY(torch.utils.data.Dataset):\n    def __init__(self, add_precents, data_src, parameters, target_cols):\n        # import data from csv file if necessary\n        self.data = data_src\n        # store info about data source  \n        self.target_cols = target_cols\n        self.parameters = parameters\n        self.data['Y'] = self.data['Y'].rank(method='first')\n        if add_precents == 0:\n                self.data['Class'] = pd.qcut(self.data['Y'], 100, labels = False) + 1\n        else:\n                self.data['Class'] = pd.qcut(self.data['Y'], 10, labels = False, duplicates='drop') + 1\n        \n    def __getitem__(self, idx):\n        # get the parameters x and the target y\n        x = self.data[self.parameters].iloc[idx]\n        y = self.data[self.target_cols].iloc[idx]\n        x = torch.tensor(x.values, dtype=torch.float32)\n        y = torch.tensor(y.values, dtype=torch.float32)\n\n        return x, y\n\n    def __len__(self):\n        return self.data.shape[0] # Returning length (shape)\n\ndef train_model(model, dataloader, epochs, optimizer, loss_fn):\n    for epoch in range(epochs):\n        model.train()  # Set the model to training mode\n        for data, targets in dataloader:\n            data, targets = data.to(device), targets.to(device).long().squeeze()\n            optimizer.zero_grad()\n            outputs = model(data)\n            loss = loss_fn(outputs, targets)\n            loss.backward()\n            optimizer.step()\n\ndef evaluate_model(model, dataloader):\n    model.eval()  # Set the model to evaluation mode\n    total, correct = 0, 0\n    with torch.no_grad():\n        for data, targets in dataloader:\n            data, targets = data.to(device), targets.to(device).long().squeeze()\n            outputs = model(data)\n            _, predicted = torch.max(outputs.data, 1)\n            total += targets.size(0)\n            correct += (predicted == targets).sum().item()\n    return 100 * correct / total\n\n# Model without Y definition\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = nn.Sequential(\n    nn.Linear(10, 10),\n    nn.ReLU(),\n    nn.Linear(10, 10),\n    nn.ReLU(),\n    nn.Linear(10, 10),\n    nn.ReLU(),\n    nn.Linear(10, 10),\n    nn.ReLU(),\n    nn.LogSoftmax(dim=1)\n).to(device)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodelY = nn.Sequential(\n    nn.Linear(11, 10),  # Adjust input size to match the number of input features\n    nn.ReLU(),\n    nn.Linear(10, 10),\n    nn.ReLU(),\n    nn.Linear(10, 10),\n    nn.ReLU(),\n    nn.Linear(10, 10),\n    nn.ReLU(),\n    nn.LogSoftmax(dim=1)\n).to(device)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodelPrecents = nn.Sequential(\n    nn.Linear(10, 100),  # Adjust input size to match the number of input features\n    nn.ReLU(),\n    nn.Linear(100, 100),\n    nn.ReLU(),\n    nn.Linear(100, 100),\n    nn.ReLU(),\n    nn.Linear(100, 100),\n    nn.ReLU(),\n    nn.LogSoftmax(dim=1)\n).to(device)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodelPrecentsY = nn.Sequential(\n    nn.Linear(11, 100),  # Adjust input size to match the number of input features\n    nn.ReLU(),\n    nn.Linear(100, 100),\n    nn.ReLU(),\n    nn.Linear(100, 100),\n    nn.ReLU(),\n    nn.Linear(100, 100),\n    nn.ReLU(),\n    nn.LogSoftmax(dim=1)\n).to(device)\n\n# Data loading\ncsv_file = r\"C:\\Users\\zlesh\\Downloads\\diabetes.csv\"\ndataSet = pd.read_csv(csv_file, sep = '\\t')\ntrain_data, test_data = train_test_split(dataSet, train_size = 0.8, shuffle = True) # Load random parts of dataset\nparameters = ['AGE', 'SEX', 'BMI', 'BP', 'S1', 'S2', 'S3', 'S4', 'S5', 'S6']\ntarget_cols = ['Class']\ndiabetes_dataset = data(1, train_data, parameters, target_cols)\ndiabetes_dataloader = DataLoader(diabetes_dataset, batch_size = 10)\nstats, targets = next(iter(diabetes_dataloader))\nprint(\"First Mini-Batch example: \")\nprint(stats)\nprint(targets)\n\nepochs = 750 # number of single passes on the network\nloss_fn = nn.NLLLoss(ignore_index = 10)\nloss_fnPrecents = nn.NLLLoss(ignore_index = 100) # negative log likehood loss function while ignoring the precentiles classes\noptimizer = torch.optim.SGD(model.parameters(), lr=0.00035) # optimizer for gradient decent with a learning rate of 0.01\n\n# Training for Class without 'Y' \ntrain_model(model, diabetes_dataloader, epochs, optimizer, loss_fn)\naccuracy = evaluate_model(model, diabetes_dataloader)\nprint(f\"Accuracy of the model excluding 'Y' column on the TRAINED dataset: {accuracy:.2f}%\")\n\nparameters.append('Y')\ndiabetesY_dataset = dataY(1, train_data, parameters, target_cols)\ndiabetesY_dataloader = DataLoader(diabetesY_dataset, batch_size = 10)\nstats, targets = next(iter(diabetesY_dataloader))\n# Training for Class with 'Y'\ntrain_model(modelY, diabetesY_dataloader, epochs, optimizer, loss_fn)\naccuracy = evaluate_model(modelY, diabetesY_dataloader)\nprint(f\"Accuracy of the model including 'Y' column on the TRAINED dataset: {accuracy:.2f}%\")\n\n# Training with remaining random 20% of the database\nparameters.remove('Y')\nTrainData = data(1, test_data, parameters, target_cols)\ndiabetes_dataloader = DataLoader(TrainData, batch_size = len(TrainData))\nDataTest, TargetsTest = next(iter(diabetes_dataloader))\nDataTest = DataTest.to(device)\nTargetsTest = TargetsTest.to(device)\naccuracy = evaluate_model(model, diabetes_dataloader)\nprint(f\"Accuracy of the model excluding 'Y' column on the TESTED dataset: {accuracy:.2f}%\") # test data without 'Y'\n\nparameters.append('Y')\nTrainYData = dataY(1, test_data, parameters, target_cols)\ndiabetesY_dataloader = DataLoader(TrainYData, batch_size = len(TrainYData))\nDataYTest, TargetsYTest = next(iter(diabetesY_dataloader))\naccuracy = evaluate_model(modelY, diabetesY_dataloader)\nprint(f\"Accuracy of the model including 'Y' column on the TESTED dataset: {accuracy:.2f}%\") # test data with 'Y'\n\nparameters.remove('Y')\ndiabetes_dataset = data(0, train_data, parameters, target_cols)\ndiabetes_dataloader = DataLoader(diabetes_dataset, batch_size = 10)\nstats, targets = next(iter(diabetes_dataloader))\n\n# Training for Class without 'Y' \ntrain_model(modelPrecents, diabetes_dataloader, epochs, optimizer, loss_fnPrecents)\naccuracy = evaluate_model(modelPrecents, diabetes_dataloader)\nprint(f\"Accuracy of the model excluding 'Y' column on the TRAINED dataset (precentiles 1-100): {accuracy:.2f}%\")\n\nparameters.append('Y')\ndiabetes_datasetY = dataY(0, train_data, parameters, target_cols)\ndiabetesY_dataloader = DataLoader(diabetesY_dataset, batch_size = 10)\n# Training for Class with 'Y'\ntrain_model(modelPrecentsY, diabetesY_dataloader, epochs, optimizer, loss_fnPrecents)\naccuracy = evaluate_model(modelPrecentsY, diabetesY_dataloader)\nprint(f\"Accuracy of the model including 'Y' column on the TRAINED dataset (precentiles 1-100): {accuracy:.2f}%\")\n\nparameters.remove('Y')\n# Training with remaining random 20% of the database\nTrainData = data(0, test_data, parameters, target_cols)\ndiabetes_dataloader = DataLoader(TrainData, batch_size = len(TrainData))\nDataTest, TargetsTest = next(iter(diabetes_dataloader))\nDataTest = DataTest.to(device)\nTargetsTest = TargetsTest.to(device)\naccuracy = evaluate_model(modelPrecents, diabetes_dataloader)\nprint(f\"Accuracy of the model excluding 'Y' column on the TESTED dataset (precentiles 1-100): {accuracy:.2f}%\") # test data without 'Y'\n\nparameters.append('Y')\nTrainYData = dataY(0, test_data, parameters, target_cols)\ndiabetesY_dataloader = DataLoader(TrainYData, batch_size = len(TrainYData))\nDataYTest, TargetsYTest = next(iter(diabetesY_dataloader))\naccuracy = evaluate_model(modelPrecentsY, diabetesY_dataloader)\nprint(f\"Accuracy of the model including 'Y' column on the TESTED dataset (precentiles 1-100): {accuracy:.2f}%\") # test data with 'Y'",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}
